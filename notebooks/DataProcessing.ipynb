{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d5481",
   "metadata": {},
   "source": [
    "# Descargar el dataset desde kaggle\n",
    "\n",
    "Para poder descargar el dataset usado en el modelo ejecuta el siguiente comando, ten en cuenta que estamos usando kaggle para esto y debes instalarlo y configurar la apiKey.\n",
    "\n",
    "`pip install kaggle`\n",
    "\n",
    "`kaggle datasets download -d grassknoted/asl-alphabet`\n",
    "\n",
    "`kaggle datasets download datamunge/sign-language-mnist`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c015b",
   "metadata": {},
   "source": [
    "#### Mover Imagenes de test a train para hacer la división personalizada, asi cumplir con un 80 train / 20 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d216c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_test_images():\n",
    "    \"\"\"\n",
    "    Moves test images to their corresponding letter folder in the train directory.\n",
    "    \"\"\"\n",
    "    source_dir = '../data/raw/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
    "    train_dir = '../data/raw/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Error: Source directory not found at {source_dir}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        image_files = [f for f in os.listdir(source_dir) if f.endswith('.jpg')]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not list files in {source_dir}. It might not be a directory.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    for filename in image_files:\n",
    "        letter = filename.split('_')[0]\n",
    "\n",
    "        destination_folder = os.path.join(train_dir, letter)\n",
    "\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "        try:\n",
    "            shutil.move(source_path, destination_path)\n",
    "            print(f\"Moved {filename} to {destination_folder}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Could not find {filename} to move.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while moving {filename}: {e}\")\n",
    "\n",
    "\n",
    "move_test_images()\n",
    "print(\"Script finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25aa4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 2401 images to ../data/processed/train/R\n",
      "Copied 600 images to ../data/processed/test/R\n",
      "Copied 2401 images to ../data/processed/train/U\n",
      "Copied 600 images to ../data/processed/test/U\n",
      "Copied 2401 images to ../data/processed/train/I\n",
      "Copied 600 images to ../data/processed/test/I\n",
      "Copied 2401 images to ../data/processed/train/N\n",
      "Copied 600 images to ../data/processed/test/N\n",
      "Copied 2401 images to ../data/processed/train/G\n",
      "Copied 600 images to ../data/processed/test/G\n",
      "Copied 2401 images to ../data/processed/train/Z\n",
      "Copied 600 images to ../data/processed/test/Z\n",
      "Copied 2401 images to ../data/processed/train/T\n",
      "Copied 600 images to ../data/processed/test/T\n",
      "Copied 2401 images to ../data/processed/train/S\n",
      "Copied 600 images to ../data/processed/test/S\n",
      "Copied 2401 images to ../data/processed/train/A\n",
      "Copied 600 images to ../data/processed/test/A\n",
      "Copied 2401 images to ../data/processed/train/F\n",
      "Copied 600 images to ../data/processed/test/F\n",
      "Copied 2401 images to ../data/processed/train/O\n",
      "Copied 600 images to ../data/processed/test/O\n",
      "Copied 2401 images to ../data/processed/train/H\n",
      "Copied 600 images to ../data/processed/test/H\n",
      "Copied 2400 images to ../data/processed/train/del\n",
      "Copied 600 images to ../data/processed/test/del\n",
      "Copied 2401 images to ../data/processed/train/nothing\n",
      "Copied 600 images to ../data/processed/test/nothing\n",
      "Copied 2401 images to ../data/processed/train/space\n",
      "Copied 600 images to ../data/processed/test/space\n",
      "Copied 2401 images to ../data/processed/train/M\n",
      "Copied 600 images to ../data/processed/test/M\n",
      "Copied 2401 images to ../data/processed/train/J\n",
      "Copied 600 images to ../data/processed/test/J\n",
      "Copied 2401 images to ../data/processed/train/C\n",
      "Copied 600 images to ../data/processed/test/C\n",
      "Copied 2401 images to ../data/processed/train/D\n",
      "Copied 600 images to ../data/processed/test/D\n",
      "Copied 2401 images to ../data/processed/train/V\n",
      "Copied 600 images to ../data/processed/test/V\n",
      "Copied 2401 images to ../data/processed/train/Q\n",
      "Copied 600 images to ../data/processed/test/Q\n",
      "Copied 2401 images to ../data/processed/train/X\n",
      "Copied 600 images to ../data/processed/test/X\n",
      "Copied 2401 images to ../data/processed/train/E\n",
      "Copied 600 images to ../data/processed/test/E\n",
      "Copied 2401 images to ../data/processed/train/B\n",
      "Copied 600 images to ../data/processed/test/B\n",
      "Copied 2401 images to ../data/processed/train/K\n",
      "Copied 600 images to ../data/processed/test/K\n",
      "Copied 2401 images to ../data/processed/train/L\n",
      "Copied 600 images to ../data/processed/test/L\n",
      "Copied 2401 images to ../data/processed/train/Y\n",
      "Copied 600 images to ../data/processed/test/Y\n",
      "Copied 2401 images to ../data/processed/train/P\n",
      "Copied 600 images to ../data/processed/test/P\n",
      "Copied 2401 images to ../data/processed/train/W\n",
      "Copied 600 images to ../data/processed/test/W\n",
      "Data splitting finished.\n"
     ]
    }
   ],
   "source": [
    "def split_data(source_dir, processed_dir, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits the data from source_dir into training and testing sets\n",
    "    and saves them in processed_dir.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): The path to the directory containing the raw data,\n",
    "                          with subdirectories for each class.\n",
    "        processed_dir (str): The path to the directory where the processed\n",
    "                             (split) data will be saved.\n",
    "        split_ratio (float): The ratio of training data to the total data.\n",
    "    \"\"\"\n",
    "    train_dir = os.path.join(processed_dir, 'train')\n",
    "    test_dir = os.path.join(processed_dir, 'test')\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Error: Source directory not found at {source_dir}\")\n",
    "        return\n",
    "\n",
    "    for letter_folder in os.listdir(source_dir):\n",
    "        letter_path = os.path.join(source_dir, letter_folder)\n",
    "        if os.path.isdir(letter_path):\n",
    "            train_letter_dir = os.path.join(train_dir, letter_folder)\n",
    "            test_letter_dir = os.path.join(test_dir, letter_folder)\n",
    "            os.makedirs(train_letter_dir, exist_ok=True)\n",
    "            os.makedirs(test_letter_dir, exist_ok=True)\n",
    "\n",
    "            images = [f for f in os.listdir(letter_path) if os.path.isfile(os.path.join(letter_path, f))]\n",
    "            random.shuffle(images)\n",
    "\n",
    "            split_point = math.ceil(len(images) * split_ratio)\n",
    "            train_images = images[:split_point]\n",
    "            test_images = images[split_point:]\n",
    "\n",
    "            for image in train_images:\n",
    "                source_image_path = os.path.join(letter_path, image)\n",
    "                dest_image_path = os.path.join(train_letter_dir, image)\n",
    "                shutil.copyfile(source_image_path, dest_image_path)\n",
    "            \n",
    "            print(f\"Copied {len(train_images)} images to {train_letter_dir}\")\n",
    "\n",
    "            for image in test_images:\n",
    "                source_image_path = os.path.join(letter_path, image)\n",
    "                dest_image_path = os.path.join(test_letter_dir, image)\n",
    "                shutil.copyfile(source_image_path, dest_image_path)\n",
    "\n",
    "            print(f\"Copied {len(test_images)} images to {test_letter_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "SOURCE_DATA_DIR = '../data/raw/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "PROCESSED_DATA_DIR = '../data/processed'\n",
    "    \n",
    "split_data(SOURCE_DATA_DIR, PROCESSED_DATA_DIR)\n",
    "print(\"Data splitting finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c247d",
   "metadata": {},
   "source": [
    "# Normalización y preprocesamiento de datos\n",
    "1. Normalizar\n",
    "2. Convertir a escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "934ce40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf27a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69628 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n",
      "Class indices: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}\n",
      "Found 17400 images belonging to 29 classes.\n",
      "Class indices: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = '../data/processed/train'\n",
    "TEST_DIR = '../data/processed/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101113a7",
   "metadata": {},
   "source": [
    "## Arquitectura de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a6d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">61,440,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m61,440,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │        \u001b[38;5;34m14,877\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,455,389</span> (234.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,455,389\u001b[0m (234.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,455,389</span> (234.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,455,389\u001b[0m (234.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(120000,)),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(29, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ee7bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67712</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">34,669,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67712\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m34,669,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │        \u001b[38;5;34m14,877\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,777,181</span> (132.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,777,181\u001b[0m (132.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,777,181</span> (132.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,777,181\u001b[0m (132.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604461b",
   "metadata": {},
   "source": [
    "## **Entrenamiento y guardado del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73308c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d04a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.2305 - loss: 2.6487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jepolancos/projects/hands-unmuted/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78787, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1172s\u001b[0m 538ms/step - accuracy: 0.2306 - loss: 2.6484 - val_accuracy: 0.7879 - val_loss: 0.6132\n",
      "Epoch 2/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.7045 - loss: 0.8791\n",
      "Epoch 2: val_accuracy improved from 0.78787 to 0.90603, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1160s\u001b[0m 533ms/step - accuracy: 0.7045 - loss: 0.8790 - val_accuracy: 0.9060 - val_loss: 0.2632\n",
      "Epoch 3/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8164 - loss: 0.5421\n",
      "Epoch 3: val_accuracy improved from 0.90603 to 0.94598, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1136s\u001b[0m 522ms/step - accuracy: 0.8164 - loss: 0.5421 - val_accuracy: 0.9460 - val_loss: 0.1558\n",
      "Epoch 4/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.8597 - loss: 0.4074\n",
      "Epoch 4: val_accuracy did not improve from 0.94598\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1153s\u001b[0m 530ms/step - accuracy: 0.8597 - loss: 0.4074 - val_accuracy: 0.9043 - val_loss: 0.2686\n",
      "Epoch 5/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.8802 - loss: 0.3546\n",
      "Epoch 5: val_accuracy improved from 0.94598 to 0.96655, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 528ms/step - accuracy: 0.8802 - loss: 0.3546 - val_accuracy: 0.9666 - val_loss: 0.1001\n",
      "Epoch 6/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.8970 - loss: 0.3106\n",
      "Epoch 6: val_accuracy improved from 0.96655 to 0.96920, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1166s\u001b[0m 536ms/step - accuracy: 0.8970 - loss: 0.3106 - val_accuracy: 0.9692 - val_loss: 0.0867\n",
      "Epoch 7/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.9088 - loss: 0.2707\n",
      "Epoch 7: val_accuracy improved from 0.96920 to 0.97414, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1165s\u001b[0m 535ms/step - accuracy: 0.9088 - loss: 0.2707 - val_accuracy: 0.9741 - val_loss: 0.0765\n",
      "Epoch 8/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.9165 - loss: 0.2493\n",
      "Epoch 8: val_accuracy improved from 0.97414 to 0.97782, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1170s\u001b[0m 537ms/step - accuracy: 0.9165 - loss: 0.2493 - val_accuracy: 0.9778 - val_loss: 0.0664\n",
      "Epoch 9/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.9232 - loss: 0.2331\n",
      "Epoch 9: val_accuracy improved from 0.97782 to 0.98385, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1199s\u001b[0m 551ms/step - accuracy: 0.9232 - loss: 0.2331 - val_accuracy: 0.9839 - val_loss: 0.0484\n",
      "Epoch 10/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.9315 - loss: 0.2051\n",
      "Epoch 10: val_accuracy improved from 0.98385 to 0.98833, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1172s\u001b[0m 538ms/step - accuracy: 0.9315 - loss: 0.2051 - val_accuracy: 0.9883 - val_loss: 0.0364\n",
      "Epoch 11/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9336 - loss: 0.2006\n",
      "Epoch 11: val_accuracy did not improve from 0.98833\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 528ms/step - accuracy: 0.9336 - loss: 0.2006 - val_accuracy: 0.9811 - val_loss: 0.0555\n",
      "Epoch 12/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.9387 - loss: 0.1835\n",
      "Epoch 12: val_accuracy did not improve from 0.98833\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1151s\u001b[0m 529ms/step - accuracy: 0.9387 - loss: 0.1835 - val_accuracy: 0.9876 - val_loss: 0.0388\n",
      "Epoch 13/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.9415 - loss: 0.1769\n",
      "Epoch 13: val_accuracy did not improve from 0.98833\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 535ms/step - accuracy: 0.9415 - loss: 0.1769 - val_accuracy: 0.9840 - val_loss: 0.0441\n",
      "Epoch 14/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.9448 - loss: 0.1690\n",
      "Epoch 14: val_accuracy did not improve from 0.98833\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1159s\u001b[0m 533ms/step - accuracy: 0.9448 - loss: 0.1690 - val_accuracy: 0.9824 - val_loss: 0.0494\n",
      "Epoch 15/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.9473 - loss: 0.1653\n",
      "Epoch 15: val_accuracy improved from 0.98833 to 0.99103, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1156s\u001b[0m 531ms/step - accuracy: 0.9473 - loss: 0.1653 - val_accuracy: 0.9910 - val_loss: 0.0265\n",
      "Epoch 16/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.9476 - loss: 0.1604\n",
      "Epoch 16: val_accuracy did not improve from 0.99103\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1158s\u001b[0m 532ms/step - accuracy: 0.9476 - loss: 0.1604 - val_accuracy: 0.9853 - val_loss: 0.0481\n",
      "Epoch 17/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.9489 - loss: 0.1607\n",
      "Epoch 17: val_accuracy did not improve from 0.99103\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 529ms/step - accuracy: 0.9489 - loss: 0.1607 - val_accuracy: 0.9753 - val_loss: 0.0732\n",
      "Epoch 18/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.9516 - loss: 0.1495\n",
      "Epoch 18: val_accuracy improved from 0.99103 to 0.99195, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1156s\u001b[0m 531ms/step - accuracy: 0.9516 - loss: 0.1495 - val_accuracy: 0.9920 - val_loss: 0.0244\n",
      "Epoch 19/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.9516 - loss: 0.1509\n",
      "Epoch 19: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1153s\u001b[0m 530ms/step - accuracy: 0.9516 - loss: 0.1509 - val_accuracy: 0.9863 - val_loss: 0.0395\n",
      "Epoch 20/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.9541 - loss: 0.1425\n",
      "Epoch 20: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 528ms/step - accuracy: 0.9541 - loss: 0.1425 - val_accuracy: 0.9916 - val_loss: 0.0249\n",
      "Epoch 21/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.9575 - loss: 0.1342\n",
      "Epoch 21: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1159s\u001b[0m 532ms/step - accuracy: 0.9575 - loss: 0.1342 - val_accuracy: 0.9896 - val_loss: 0.0309\n",
      "Epoch 22/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.9555 - loss: 0.1399\n",
      "Epoch 22: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 532ms/step - accuracy: 0.9555 - loss: 0.1399 - val_accuracy: 0.9914 - val_loss: 0.0290\n",
      "Epoch 23/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.9597 - loss: 0.1276\n",
      "Epoch 23: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 531ms/step - accuracy: 0.9597 - loss: 0.1276 - val_accuracy: 0.9910 - val_loss: 0.0287\n",
      "Epoch 24/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.9594 - loss: 0.1320\n",
      "Epoch 24: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 529ms/step - accuracy: 0.9594 - loss: 0.1320 - val_accuracy: 0.9906 - val_loss: 0.0270\n",
      "Epoch 25/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9593 - loss: 0.1289\n",
      "Epoch 25: val_accuracy did not improve from 0.99195\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1147s\u001b[0m 527ms/step - accuracy: 0.9593 - loss: 0.1289 - val_accuracy: 0.9885 - val_loss: 0.0322\n",
      "Epoch 26/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.9609 - loss: 0.1279\n",
      "Epoch 26: val_accuracy improved from 0.99195 to 0.99557, saving model to ../models/best_asl_model.keras\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 528ms/step - accuracy: 0.9609 - loss: 0.1279 - val_accuracy: 0.9956 - val_loss: 0.0125\n",
      "Epoch 27/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9579 - loss: 0.1361\n",
      "Epoch 27: val_accuracy did not improve from 0.99557\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1150s\u001b[0m 528ms/step - accuracy: 0.9579 - loss: 0.1361 - val_accuracy: 0.9668 - val_loss: 0.0990\n",
      "Epoch 28/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.9615 - loss: 0.1235\n",
      "Epoch 28: val_accuracy did not improve from 0.99557\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1145s\u001b[0m 526ms/step - accuracy: 0.9615 - loss: 0.1235 - val_accuracy: 0.9906 - val_loss: 0.0281\n",
      "Epoch 29/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.9619 - loss: 0.1223\n",
      "Epoch 29: val_accuracy did not improve from 0.99557\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1140s\u001b[0m 524ms/step - accuracy: 0.9619 - loss: 0.1223 - val_accuracy: 0.9949 - val_loss: 0.0161\n",
      "Epoch 30/30\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.9635 - loss: 0.1174\n",
      "Epoch 30: val_accuracy did not improve from 0.99557\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 523ms/step - accuracy: 0.9635 - loss: 0.1174 - val_accuracy: 0.9922 - val_loss: 0.0244\n",
      "Trainning finished, best model saved at: ../models/best_asl_model.keras\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '../models/best_asl_model.keras'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=FILE_PATH,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "print(\"Trainning finished, best model saved at:\", FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ab9b6",
   "metadata": {},
   "source": [
    "### **Evaluación del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0486719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 117ms/step - accuracy: 0.9954 - loss: 0.0132\n",
      "Test accuracy: 0.9956\n",
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 117ms/step - accuracy: 0.9954 - loss: 0.0132\n",
      "Test accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(FILE_PATH)\n",
    "test_loss, test_accuracy = loaded_model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f82fd",
   "metadata": {},
   "source": [
    "### **Función de predicción del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bcde542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Índice de clase predicho: 9, Confianza: 0.9999\n",
      "Nombre de clase predicho: J\n",
      "\n",
      "Resultado final para ../data/test_images/2_test.jpg: J\n",
      "Índice de clase predicho: 9, Confianza: 0.9999\n",
      "Nombre de clase predicho: J\n",
      "\n",
      "Resultado final para ../data/test_images/2_test.jpg: J\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    model = keras.models.load_model(FILE_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def predict_image(model, img_path, class_indices):\n",
    "    \"\"\"Carga una imagen, la preprocesa y predice su clase.\"\"\"\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(200, 200))\n",
    "    \n",
    "\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "\n",
    "    img_array /= 255.0\n",
    "    \n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "\n",
    "\n",
    "    index_to_class = {v: k for k, v in class_indices.items()}\n",
    "    \n",
    "    predicted_class_name = index_to_class[predicted_class_index]\n",
    "    \n",
    "    print(f\"Índice de clase predicho: {predicted_class_index}, Confianza: {confidence:.4f}\")\n",
    "    print(f\"Nombre de clase predicho: {predicted_class_name}\")\n",
    "    \n",
    "    return predicted_class_name\n",
    "\n",
    "try:\n",
    "    image_path = '../data/test_images/2_test.jpg'\n",
    "    predicted_class = predict_image(model, image_path, train_generator.class_indices)\n",
    "    print(f\"\\nResultado final para {image_path}: {predicted_class}\")\n",
    "except NameError:\n",
    "    print(\"Asegúrate de haber ejecutado la celda que define 'train_generator' primero.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error durante la predicción: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
